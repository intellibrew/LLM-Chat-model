{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMADhfOTyTQk6wNQLruNUiq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Darksoule123/COURSEAREA-TEST1/blob/master/FAB_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph langchain_community tavily-python langchain-core langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm_ZAu2fje3X",
        "outputId": "d348fc58-9f56-40a5-bbc8-f569f3c41da3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.14-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-0.2.34-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.22-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langgraph-checkpoint<2.0.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-1.0.6-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.13 (from langchain_community)\n",
            "  Downloading langchain-0.2.14-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n",
            "  Downloading langsmith-0.1.104-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain_community)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tiktoken>=0.5.1 (from tavily-python)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting httpx (from tavily-python)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.12.2)\n",
            "Collecting openai<2.0.0,>=1.40.0 (from langchain-openai)\n",
            "  Downloading openai-1.42.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.13->langchain_community)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain_community)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx->tavily-python)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->tavily-python)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain-openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.5.15)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->tavily-python) (1.2.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langgraph-0.2.14-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.2.12-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tavily_python-0.4.0-py3-none-any.whl (13 kB)\n",
            "Downloading langchain_core-0.2.34-py3-none-any.whl (393 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.9/393.9 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.1.22-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain-0.2.14-py3-none-any.whl (997 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-1.0.6-py3-none-any.whl (15 kB)\n",
            "Downloading langsmith-0.1.104-py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.1/149.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.42.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: tenacity, orjson, mypy-extensions, marshmallow, jsonpointer, jiter, h11, typing-inspect, tiktoken, jsonpatch, httpcore, httpx, dataclasses-json, tavily-python, openai, langsmith, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langgraph, langchain, langchain_community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed dataclasses-json-0.6.7 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.14 langchain-core-0.2.34 langchain-openai-0.1.22 langchain-text-splitters-0.2.2 langchain_community-0.2.12 langgraph-0.2.14 langgraph-checkpoint-1.0.6 langsmith-0.1.104 marshmallow-3.22.0 mypy-extensions-1.0.0 openai-1.42.0 orjson-3.10.7 tavily-python-0.4.0 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Wq3OPkvhjCI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d4a95ab-1e62-4b24-d080-735b89894985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: I want to buy an iphone 14 what is the best site to buy it \n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe iPhone 14 has not been released yet, so it's not possible to buy it from any site. \n",
            "Final Answer: The iPhone 14 is not available for purchase as it has not been released yet.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Assistant: The iPhone 14 is not available for purchase as it has not been released yet.\n",
            "--\n",
            "Time taken for this interaction: 1.81 seconds\n",
            "User: i want to buy an iphone 13 \n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe user is looking for a place to buy an iPhone 13. I should find reputable online stores where the iPhone 13 is available for purchase.\n",
            "Action: Restricted Search\n",
            "Action Input: Buy iPhone 13 online\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[{'url': 'https://www.flipkart.com/apple-iphone-13-product-red-128-gb/p/itm99b5658d148b0?pid=MOBG6VF59ZFEPEBX&marketplace=FLIPKART', 'content': 'Rating  4.6  (13,705) Buy Apple iPhone 13 online at best price with offers in India. Apple iPhone 13 (Red, 128 GB) with features and specifications include 128 GB GB ROM,\\xa0...'}, {'url': 'https://www.flipkart.com/apple-iphone-13-blue-128-gb/p/itm6c601e0a58b3c?pid=MOBG6VF5SMXPNQHG&lid=LSTMOBG6VF5SMXPNQHGMMXJDB', 'content': 'Rating  4.6  (13,706) Buy Apple iPhone 13 online at best price with offers in India. Apple iPhone 13 (Blue, 128 GB) with features and specifications include 128 GB GB ROM,\\xa0...'}, {'url': 'https://www.flipkart.com/apple-iphone-13-blue-128-gb/p/itm6c601e0a58b3c?pid=MOBG6VF5SMXPNQHG&lid=LSTMOBG6VF5SMXPNQHGH3DY6Z&marketplace=FLIPKART&store=tyy%2F4io&srno=b_1_4&otracker=browse&fm=organic&iid=64abe9c4-a452-4c64-b629-e82b784aa506.MOBG6VF5SMXPNQHG.SEARCH&ppt=None&ppn=None&ssid=jl9shz5kxs0000001688381261225', 'content': 'Rating  4.6  (13,706) Buy Apple iPhone 13 online at best price with offers in India. Apple iPhone 13 (Blue, 128 GB) with features and specifications include 128 GB GB ROM,\\xa0...'}, {'url': 'https://www.flipkart.com/apple-iphone-13-blue-128-gb/p/itm6c601e0a58b3c?pid=MOBG6VF5SMXPNQHG', 'content': 'Rating  4.6  (13,705) Buy Apple iPhone 13 online at best price with offers in India. Apple iPhone 13 (Blue, 128 GB) with features and specifications include 128 GB GB ROM,\\xa0...'}, {'url': 'https://www.flipkart.com/apple-iphone-13-blue-128-gb/p/itm6c601e0a58b3c?pid=MOBG6VF5SMXPNQHG&lid=LSTMOBG6VF5SMXPNQHGL5FN51&marketplace=FLIPKART', 'content': 'Rating  4.6  (13,705) Buy Apple iPhone 13 online at best price with offers in India. Apple iPhone 13 (Blue, 128 GB) with features and specifications include 128 GB GB ROM,\\xa0...'}, {'url': 'https://www.amazon.in/Apple-iPhone-13-128GB-Blue/dp/B09G9BL5CP', 'content': 'Rating  4.5  (28,722) iPhone 13. The most advanced dual-camera system ever on iPhone. Lightning-fast A15 Bionic chip. A big leap in battery life. Durable design.'}, {'url': 'https://www.amazon.in/Apple-iPhone-13-128GB-Midnight/dp/B09G9HD6PD', 'content': 'Rating  4.5  (28,722) iPhone 13. The most advanced dual-camera system ever on iPhone. Lightning-fast A15 Bionic chip. A big leap in battery life. Durable design.'}, {'url': 'https://www.flipkart.com/apple-iphone-13-pink-128-gb/p/itm6e30c6ee045d2', 'content': 'Rating  4.6  (13,706) Buy the iPhone 13 with cutting-edge Dual-Camera technology, the powerful A15 Bionic Chip, and enjoy flexible No Cost EMI options. Get the best of iPhone\\xa0...'}, {'url': 'https://www.amazon.in/iphone-13-offers-low-price-today/s?k=iphone+13+offers+low+price+today', 'content': '5K+ bought in past month. ₹51,999₹51,999. M.R.P: ₹59,900₹59,900. (13% off). FREE delivery Mon, 26 Aug. Or fastest delivery Tomorrow, 25 Aug.'}, {'url': 'https://www.amazon.in/Apple-iPhone-13-256GB-Product/dp/B09G9HDN4Q', 'content': 'Rating  4.5  (28,722) From its sleek design to its powerful performance and innovative features, this device has truly redefined what it means to own a premium smartphone. Design and\\xa0...'}]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe iPhone 13 can be purchased online from Flipkart and Amazon in India. These are reputable online stores with good customer ratings for the product. \n",
            "Final Answer: You can buy an iPhone 13 online from Flipkart or Amazon.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Assistant: You can buy an iPhone 13 online from Flipkart or Amazon.\n",
            "--\n",
            "Time taken for this interaction: 15.21 seconds\n",
            "User: q\n",
            "Goodbye!\n"
          ]
        }
      ],
      "source": [
        "#restricted search\n",
        "\n",
        "import time\n",
        "from typing_extensions import TypedDict\n",
        "from typing import Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain.schema import HumanMessage  # Import HumanMessage to check type\n",
        "\n",
        "# Define the State class\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# Initialize the StateGraph\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Set up API keys\n",
        "import os\n",
        "from tavily import TavilyClient\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "\n",
        "# Assuming you're working on Google Colab, you can use `get` from `google.colab` for user data.\n",
        "from google.colab import userdata\n",
        "\n",
        "openaiapikey = userdata.get('openaiapikey').strip()\n",
        "apikey = userdata.get('api_key')\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openaiapikey\n",
        "os.environ[\"TAVILY_API_KEY\"] = apikey\n",
        "\n",
        "# Initialize the language model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=10,\n",
        "    api_key=openaiapikey\n",
        ")\n",
        "\n",
        "# Custom function to restrict search to multiple sites\n",
        "def restricted_tavily_search(query: str, sites: list) -> str:\n",
        "    site_query = \" OR \".join([f\"site:{site}\" for site in sites])  # Combine sites with OR\n",
        "    restricted_query = f\"{site_query} {query}\"  # Prepend the site restriction to the query\n",
        "    return tool.run(restricted_query)\n",
        "\n",
        "# Define the sites you want to restrict the search to\n",
        "restricted_sites = [\"indiamart.com\", \"amazon.in\", \"flipkart.com\"]\n",
        "\n",
        "# Create a Tool object for LangChain agent with the restricted search function\n",
        "search_tool = Tool(\n",
        "    name=\"Restricted Search\",\n",
        "    func=lambda query: restricted_tavily_search(query, restricted_sites),  # Include the sites list directly\n",
        "    description=\"Searches using Tavily for information from specified sites.\"\n",
        ")\n",
        "\n",
        "# Initialize the agent with the language model and tools\n",
        "tools = [search_tool]\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Define the chatbot function using the agent\n",
        "def chatbot(state: State):\n",
        "    last_message = state[\"messages\"][-1]  # Get the last message object\n",
        "    if isinstance(last_message, HumanMessage):  # Ensure it's a HumanMessage\n",
        "        user_input = last_message.content  # Access the content\n",
        "    else:\n",
        "        user_input = last_message[\"content\"]  # Fallback for dictionary-like access\n",
        "\n",
        "    response = agent.run(user_input)  # Get the response from the agent\n",
        "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})  # Add response to the state\n",
        "    return state\n",
        "\n",
        "# Build the graph\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=[search_tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "# Initialize memory saver\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Compile the graph\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "# Configuration\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# Main loop for user interaction\n",
        "state = {\"messages\": []}  # Initialize the state\n",
        "while True:\n",
        "    user_input = input(\"User: \")  # Capture user input\n",
        "    if user_input.lower() == \"q\":  # Exit condition\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    state[\"messages\"].append({\"role\": \"user\", \"content\": user_input})  # Add user input to state\n",
        "\n",
        "    start_time = time.time()  # Start time tracking\n",
        "\n",
        "    # Process the user input and generate response\n",
        "    state = chatbot(state)  # Pass state to chatbot function\n",
        "\n",
        "    # Print the assistant's response\n",
        "    print(f\"Assistant: {state['messages'][-1]['content']}\")\n",
        "    print(\"--\")\n",
        "\n",
        "    end_time = time.time()  # End time tracking\n",
        "    print(f\"Time taken for this interaction: {end_time - start_time:.2f} seconds\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#no restricted search\n",
        "\n",
        "import time\n",
        "from typing_extensions import TypedDict\n",
        "from typing import Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain.schema import HumanMessage  # Import HumanMessage to check type\n",
        "\n",
        "# Define the State class\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# Initialize the StateGraph\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Set up API keys\n",
        "import os\n",
        "from tavily import TavilyClient\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "\n",
        "# Assuming you're working on Google Colab, you can use `get` from `google.colab` for user data.\n",
        "from google.colab import userdata\n",
        "\n",
        "openaiapikey = userdata.get('openaiapikey').strip()\n",
        "apikey = userdata.get('api_key')\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openaiapikey\n",
        "os.environ[\"TAVILY_API_KEY\"] = apikey\n",
        "\n",
        "# Initialize the language model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=10,\n",
        "    api_key=openaiapikey\n",
        ")\n",
        "\n",
        "# Set up the search tool\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "tool = TavilySearchResults(max_results=10)\n",
        "\n",
        "# Create a Tool object for LangChain agent\n",
        "search_tool = Tool(\n",
        "    name=\"Search\",\n",
        "    func=tool.run,\n",
        "    description=\"Searches using Tavily for information.\"\n",
        ")\n",
        "\n",
        "# Initialize the agent with the language model and tools\n",
        "tools = [search_tool]\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Define the chatbot function using the agent\n",
        "def chatbot(state: State):\n",
        "    last_message = state[\"messages\"][-1]  # Get the last message object\n",
        "    if isinstance(last_message, HumanMessage):  # Ensure it's a HumanMessage\n",
        "        user_input = last_message.content  # Access the content\n",
        "    else:\n",
        "        user_input = last_message[\"content\"]  # Fallback for dictionary-like access\n",
        "\n",
        "    response = agent.run(user_input)  # Get the response from the agent\n",
        "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})  # Add response to the state\n",
        "    return state\n",
        "\n",
        "# Build the graph\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "# Initialize memory saver\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Compile the graph\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "# Configuration\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# Main loop for user interaction\n",
        "state = {\"messages\": []}  # Initialize the state\n",
        "while True:\n",
        "    user_input = input(\"User: \")  # Capture user input\n",
        "    if user_input.lower() == \"q\":  # Exit condition\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    state[\"messages\"].append({\"role\": \"user\", \"content\": user_input})  # Add user input to state\n",
        "\n",
        "    start_time = time.time()  # Start time tracking\n",
        "\n",
        "    # Process the user input and generate response\n",
        "    state = chatbot(state)  # Pass state to chatbot function\n",
        "\n",
        "    # Print the assistant's response\n",
        "    print(f\"Assistant: {state['messages'][-1]['content']}\")\n",
        "    print(\"--\")\n",
        "\n",
        "    end_time = time.time()  # End time tracking\n",
        "    print(f\"Time taken for this interaction: {end_time - start_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "bazJbn7rKhzZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}